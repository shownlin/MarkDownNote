# 影像處理相關

## SIFT

尺度不變特徵轉換（Scale-invariant feature transform 或 SIFT）是一種機器視覺的演算法用來偵測與描述影像中的局部性特徵，它在空間尺度中尋找極值點，並提取出其位置、尺度、旋轉不變數，此演算法由 David Lowe 在1999年所發表，2004年完善總結。後續的論文中也有許多基於 SIFT 改進的論文，例如 SURF 將 SIFT 的許多過程近似，達到加速的效果；PCA-SIFT利用主成分分析降低描述子的維度，減少記憶體的使用並加快配對速度。

其應用範圍包含物體辨識、機器人地圖感知與導航、影像縫合、3D模型建立、手勢辨識、影像追蹤和動作比對。

此演算法有其專利，專利擁有者為 英屬哥倫比亞大學。

![高斯差分金字塔](https://i.imgur.com/LvYGETP.png)

上圖解釋如何建立高斯差分金字塔，包含了2個Octave，每個Octave包含了5個Interval。

### 從高斯金字塔開始(差分還沒講)：

此步驟又稱為：Scale-space Extrema Detection

高斯金字塔是在Sift算子中提出來的概念，首先高斯金字塔並不是一個金字塔，而是有很多組(Octave)金字塔構成，並且每組金字塔都包含若干層(Interval)。

其中建塔步驟有以下4步驟：

1. 先將原圖片擴大一倍之後，經過高斯捲積後（其實就是高斯模糊、高斯平滑或稱高斯濾波）作為高斯金字塔的第1組第1層，再將第1組第1層圖像再次經過高斯捲積作為第1組金字塔的第2層，每層以此類推，高斯捲積函數為：
   $$
   G(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{(x - x_0)^2+(y - y_0)^2}{2\sigma^2}}
   $$
   此函數經常用在高斯模糊中(Gaussian Blur)，詳細請參考[這裡](https://blog.csdn.net/farmwang/article/details/74452750)，關於$\sigma$如何決定，繼續往下看。

2. 將$\sigma$乘以一個比例係數$k$，等到一個新的平滑因子$\sigma=k\times\sigma$，用它來平滑第1組第2層圖片，並將其結果作為第3層的圖片。

3. 不斷重複第2步驟，最後共得到L層圖像，在同一組中，且每一層圖像的尺寸都是一樣的，只有平滑係數不一樣。它們對應的平滑係數分別為：$\sigma, k\sigma, k^2\sigma, k^3\sigma,......, k^{L-1}\sigma$，其中$L=n+3$，n代表意思下面解釋。

4. 將第1組倒數第三層圖像(即平滑因子為$k^{L-3}\sigma=k^n\sigma$那一層)作比例因子為2的降取樣(donwsampling)，得到的圖片作為第2組的第1層。其中將取樣方式即做間隔取點，每兩個像素之中僅取一個，藉此把圖片大小縮為一半。
   
   然後對第2組的第1層圖片做平滑因子為$\sigma$的高斯平滑，得到第2組的第2層，就像步驟2中一樣，如此得到第2組的L層圖片，同組內的圖片尺寸也都是一樣的，只是第2組的圖片大小會是第1組圖片的一半。
   
這樣反覆執行，就可以得到一共O組，每組L層，共計$O\times L$個圖片，這些圖片就構成了高斯金字塔。

以上步驟總結：
* 在同一Octave內，不同Interval圖像的尺寸是一樣的，後一層圖片的高斯平滑因子$\sigma$是前一層圖片平滑因子的k倍
* 在不同Octave內，後一組第一個圖像是前一組倒數第三個圖像的二分之一降取樣，圖像大小是前一組的一半

![第1組的4層](https://i.imgur.com/RlmI82A.png) ![第2組的4層](https://i.imgur.com/r436cGb.png)

左圖顯示了一個高斯金字塔第1組的4個層，右圖顯示了第2組的4個層，分別是由下至上$\sigma$越來越大。

其中，高斯金字塔應該取多少組？
論文中建議：
$$
O = \lfloor 1og_2(\min(M, N))\rfloor-3
$$
$$
L = n+3
$$
上式中，
O為組數，M和N分別代表原圖的長和寬。
L代表層數，小n和大N不是同一個東西，小n代表希望在幾張圖片中尋找特徵。
可以詳見[影片](https://www.bilibili.com/video/BV1Qb411W7cK/?spm_id_from=333.788.videocard.0)第13分30秒。

為什麼是+3（意即我們做完高斯金字塔之後必須要扣掉三張圖片不能找特徵）？
因為必須做差分，此時每一組會少1張圖，再加上接下來還要求極值點，而每一組中最上面一張圖和最下面一張圖會少一個求導的方向（金字塔每一組中一張圖有X和Y方向，加上金字塔疊起來的高度有Z軸方向，而最上最下Z軸已經到頂不可導），故還要再減去2張圖。

再來，高斯模糊函數中而關於參數$\sigma$在SIFT中如何決定呢？
$$
k = \sqrt[\leftroot{-2}\uproot{2}n]{k}
$$
$$
\sigma_0=\sqrt{1.6^2-0.5^2}=1.52
$$
上式中，
n就是同希望在多少張圖片中取特徵的那個小n，平滑因子每過一層就乘上k，初始值為1.52。

為什麼是1.52？
因為作者認為照相機拍下來的圖片其實自帶一個高斯模糊效果，並不能完全還原真實情況，他認為這個模糊的因子大約落在0.5，所以事先扣掉了，希望用1.52的捲積核模糊完就會是剛好的1.6。

為什麼可以這樣做？
因為高斯模糊符合勾股定理，先用0.5的高斯核捲積完後，再用1.52的高斯核再捲積，相當於直接用1.6的高斯核直接捲積。

### 高斯差分金字塔：

又叫DOG金字塔(Difference of Gaussian)，是在高斯金字塔的基礎上構建起來的，其實生成高斯金字塔的目的就是為了構建DOG金字塔。

如最初的那張圖：
![高斯差分金字塔](https://i.imgur.com/LvYGETP.png)

DOG金字塔的第1組第1層是由高斯金字塔的第1組第2層減第1組第1層得到的。
以此類推，逐組逐層生成每一個差分圖像，所有差分圖像構成差分金字塔。

可以概括成一句話：
DOG金字塔的第o組第l層圖片，是由高斯金字塔的第o組第l+1層減去第o組第l層得到的。

![差分金字塔實際效果](https://i.imgur.com/UKp3PEx.png)

高斯差分金字塔生成的圖片大概長這樣，黑黑的看不出來什麼東西，但其實有很多人肉眼無法分辨的特徵訊息在裡面，仔細看勉強可以看到裡面有一些輪廓存在。

下面嘗試對這些DOG圖像進行歸一化，可以很明顯地看到差分圖像所蘊含的特徵，並且有一些特徵是在不同模糊程度、不同尺度下都存在的，這些特徵正是SIFT所要提取的「穩定」特徵。

![DOG進行歸一化](https://i.imgur.com/jJB3xIf.png)

此處歸一化採用normalize函数，對每個像素的intensity，進行$x^* = \frac{x-min}{max-min}$。


高斯差分金字塔的靈魂在於模擬：近大遠小，近清晰遠模糊
注意：數學上有證明此處只能使用高斯模糊來做，其他kernel就算可以作出模糊效果也不能替代高斯核


### 關鍵點確定(Keypoint Localization)

![Scale-space extrema detection](https://i.imgur.com/WooxkbH.png)

此步驟又稱為：Scale-space extrema detection

何謂極值？
看圖片，中央的X那一點，和周圍的綠色圓圈形成一個$3\times 3 \times 3$的立方體，若X是其中最大或最小值，那X就是一個極值。

而在找極值這個動作之前，
#### 必須先作閾值化：
$$
abs(val) > 0.5 \times \frac{T}{n}
$$
$$
T = 0.04
$$
其中n就是上述想要在幾張圖片中尋找特徵的那個小n，而T在論文中和openCV中都是固定值0.04(自己決定)。
val就是圖中每個像素的intensity，若它的絕對值小於$0.5 \times \frac{T}{n}$，則捨棄，認為它一定不會是關鍵點。

做完上兩步，
#### 還必須對極值點進行精確定位：
因為我們找到的極值點，是在離散空間中的極值點(像素、尺度空間都是離散的)，很有可能找到的極值點只是真正極值點附近的一個點。需要找到更精確、也許是啞像素位置(Dummy Pixel)的一個點。

利用三元二階的泰勒展開(Taylor series expansion of scale space)來得到extrema更精確的位置：
$$
f\left(\begin{bmatrix} x\\y\\\sigma \end{bmatrix}\right) = f\left(\begin{bmatrix} x_0\\y_0\\\sigma_0 \end{bmatrix}\right)+\left[ \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial \sigma}  \right] \left( \begin{bmatrix} x\\y\\\sigma \end{bmatrix} - \begin{bmatrix} x_0\\y_0\\\sigma_0 \end{bmatrix}\right) + \frac{1}{2} \left( \begin{bmatrix} x\\y\\\sigma \end{bmatrix} - \begin{bmatrix} x_0\\y_0\\\sigma_0 \end{bmatrix}\right)^T \begin{bmatrix}\frac{\partial^2 f}{\partial x\partial x}&\frac{\partial^2 f}{\partial x\partial y}&\frac{\partial^2 f}{\partial x\partial \sigma} \\ \frac{\partial^2 f}{\partial x\partial y}&\frac{\partial^2 f}{\partial y\partial y}&\frac{\partial^2 f}{\partial y\partial \sigma} \\ \frac{\partial^2 f}{\partial x\partial \sigma}&\frac{\partial^2 f}{\partial y\partial \sigma}&\frac{\partial^2 f}{\partial \sigma \partial \sigma}\end{bmatrix} \left( \begin{bmatrix} x\\y\\\sigma \end{bmatrix} - \begin{bmatrix} x_0\\y_0\\\sigma_0 \end{bmatrix}\right)
$$

寫成向量形式：
$$
f(X) = f(X_0) + \frac{\partial f^T}{\partial X}\Delta X + \frac{1}{2}\Delta X^T\frac{\partial f^2}{\partial X^2}\Delta X
$$

其中，$X_0$就是圖片中X那一點，在此處作一個泰勒展開，相當於原始函數在$X_0$處的一個逼近。
那要怎麼利用上式求極值點？
對$f(X)$微分：
$$
\frac{\partial f(X)}{\partial X}=\frac{\partial f^T}{\partial X}+\frac{1}{2}\left( \frac{\partial^2 f}{\partial X^2}+\frac{\partial^2 f^T}{\partial X^2} \right)\Delta X = \frac{\partial f^T}{\partial X}+\frac{\partial^2 f}{\partial X^2}\Delta X
$$
令導數為0求極值解得：
$$
\Delta X = \frac{\partial^2 f^{-1}}{\partial X^2} \cdot \frac{\partial f}{\partial X}
$$
代回$f(X)$：
$$
\begin{aligned}
f(X) &= f(X_0) + \frac{\partial f^T}{\partial X}\Delta X + \frac{1}{2}\left( -\frac{\partial^2 f^{-1}}{\partial X^2}\cdot\frac{\partial f}{\partial X} \right)^T \frac{\partial^2 f}{\partial X^2}\left( -\frac{\partial^2 f^{-1}}{\partial X^2}\cdot\frac{\partial f}{\partial X} \right)\\
&= f(X_0) + \frac{\partial f^T}{\partial X}\Delta X + \frac{1}{2}\cdot\frac{\partial f^T}{\partial X}\cdot\frac{\partial^2 f^{-T}}{\partial X^2}\cdot\frac{\partial^2 f}{\partial X^2}\cdot\frac{\partial f^{-1}}{\partial X^2}\cdot\frac{\partial f}{\partial X}\\
&= f(X_0) + \frac{\partial f^T}{\partial X}\Delta X + \frac{1}{2}\cdot\frac{\partial f^T}{\partial X}\cdot\frac{\partial^2 f^{-1}}{\partial X^2}\cdot\frac{\partial f}{\partial X}\\
&= f(X_0) + \frac{\partial f^T}{\partial X}\Delta X + \frac{1}{2}\frac{\partial f^T}{\partial X}(-\Delta X)\\
&= f(X_0) + \frac{1}{2}\frac{\partial f^T}{\partial X}\Delta X
\end{aligned}
$$

還有一些細節問題：疊代次數限制、解超出一定範圍捨去

求得的$\Delta X$即為圖片中X相對於極值點的位移量。
再代回$f(x)$繼續逼近，一直到$\Delta X$低於某個量，如$\Delta X < 0.5$之類的，代表$\Delta X$已收斂。

接著，捨去低對比度的點：
$$
\text{if}\quad\left| f(x) \right|<\frac{T}{n},\quad \text{drop the point x}
$$
基本上意思就是：如果intensity of extrema的值小於某個threshold，則有可能是噪聲，應該從keypoint的候選點之中剔除。這個threshold在OpenCV也被稱為contrastThreshold。

另外，此處的微分該怎麼做？
#### 利用「有限差分求導法」：

用差商來代替微分，在給定自變數的兩個值之間，函數值的差與變數差的商值稱為差商。函數f(x)在兩點x0與x1間的差商可以寫為：$f_i(x)=\frac{f(x)-f(x_i)}{x-x_i},\quad i=0, 1, 2,...$
![有限差分求導法X和Y](https://i.imgur.com/ilHcPOD.png)

圖中，數字代表下標。
下式中，h是像素之間的距離，取多少無所謂。

$$
\begin{aligned}
\left( \frac{\partial f}{\partial x} \right)&=\frac{f_1-f_3}{2h}\\
\left( \frac{\partial f}{\partial y} \right)&=\frac{f_2-f_4}{2h}\\
\left( \frac{\partial^2 f}{\partial x^2} \right)&=\frac{f_1+f_3-2f_0}{h^2}\\
\left( \frac{\partial^2 f}{\partial y^2} \right)&=\frac{f_2+f_4-2f_0}{h^2}\\
\left( \frac{\partial^2 f}{\partial x \partial y} \right)&=\frac{(f_8+f_6)-(f_5+f_7)}{4h^2}
\end{aligned}
$$

![有限差分求導法sigma x](https://i.imgur.com/OOb1zS5.png)
$$
\begin{aligned}
\left( \frac{\partial f}{\partial \sigma} \right)&=\frac{f_2-f_4}{2h}\\
\left( \frac{\partial^2 f}{\partial \sigma^2} \right)&=\frac{f_2+f_4-2f_0}{h^2}\\
\left( \frac{\partial^2 f}{\partial x \partial \sigma} \right)&=\frac{(f_8+f_6)-(f_5-f_7)}{4h^2}
\end{aligned}
$$

![有限差分求導法sigma y](https://i.imgur.com/xvHazJp.png)
$$
\left( \frac{\partial^2 f}{\partial y \partial \sigma} \right)=\frac{(f_8+f_6)-(f_5+f_7)}{4h^2}
$$



接著是最後一步，
#### 邊緣效應的去除：

需要用到[Hessian matrix](https://zh.wikipedia.org/wiki/黑塞矩陣)（所有的二階偏導放進矩陣之中），用以描述函數局的曲率，用以檢測X和Y方向的曲率，希望兩者差不多，否則可能是個edge。

數學上的結論：Hessian matrix的特徵值(eigenvalue)跟曲率成正比，但求特徵值麻煩，用trace和行列式來替代。
trace: eigenvalue之和
determinant: eigenvalue之乘積

$$
H(x,y) = \begin{bmatrix} D_{xx}(x,y) & D_{xy}(x,y) \\ D_{xy}(x,y) & D_{yy}(x,y)\end{bmatrix}\\
Tr(H) = D_{xx}+D_{yy} = \alpha + \beta\\
Det(H) = D_{xx}D_{yy}-(D_{xy}^2) = \alpha\cdot\beta
$$

其中：
假設H有2個特徵值$\alpha$和$\beta$，
$\alpha>\beta$ 且 $\alpha=\gamma\beta$
(顯然$\gamma \ge 1$)

若$Det(H)<0$，則捨去點X。(原因：曲率異號，故有邊緣效應)

$$
\frac{Tr(H)^2}{Det(H)}=\frac{(\alpha+\beta)^2}{\alpha\beta}=\frac{(\gamma\beta+\beta)^2}{\gamma\beta^2}=\frac{(\gamma+1)^2}{\gamma}
$$

此處是一個[對勾函數](https://zh.wikipedia.org/wiki/對勾函数)：
因為$\frac{(\gamma+1)^2}{\gamma} = \gamma + \frac{1}{\gamma} + 2$
詳細介紹影片可看[這裡](https://youtu.be/fVJelfkGX1Q)
此函數是對勾函數向上平移2，但最小值仍然在$\gamma=1$處，又由於已知$\gamma>1$，此處是單調遞增的函數。


若不滿足$\frac{Tr(H)^2}{Det(H)}<\frac{(\gamma^*+1)^2}{\gamma^*}$，捨去點X。
(原因：我們希望$\gamma$要大於某個閾值$\gamma^*$，又此函數單調遞增，則$\frac{(\gamma+1)^2}{\gamma} > \frac{(\gamma^*+1)^2}{\gamma^*}$才是我們要的)

DoG會把edge算進potential keypoint，為了要移除這些edge，會計算該potential keypoint的eigen value，如果它們之間的比值超過edgeThreshold，則該keypoint將被剔除，在論文中$\gamma^* = 10$。

到此，剔除了低對比及edge的keypoint，剩下來的，就是所需要的feature point。


### Orientation Assignment（為關鍵點賦予方向）

統計以特徵點為圓心，以該特徵點所在的高斯圖像的尺度的1.5倍為半徑的圓內，所有的像素梯度方向及其梯度幅值，並作$1.5\sigma$的高斯濾波。

![主方向](https://i.imgur.com/xygyzDk.png)

(在最接近關鍵點尺度的高斯圖片上面找，而不是高斯差分圖片上面找)
也就是說，針對離關鍵點最近的高斯圖片中最接近關鍵點的點X，統計其周遭的梯度方向，共分成36個方向。
並且其梯度大小在累加時要乘上高斯濾波的權重作加權總和。
其中統計量最高的的方向稱為主方向，若有某一個次小的方向大於主方向的80%，那它就是輔方向。

![賦予方向](https://i.imgur.com/cE6Ict2.png)

例如這張圖，圓圈大小代表該關鍵點的尺度大小，一條線所指的代表其主方向，有兩條線代表有輔方向。

### Keypoint Descriptor（關鍵點描述器）

為什麼要使用描述器？
因為我們用SIFT不只是為了在一張圖之中找到關鍵點，希望能在兩張圖中找到相對應的關鍵點（主體相同，但拍攝角度、手法不同的兩張圖）以進行匹配。
在論文中使用128維的向量來製作Descriptor。

![描述器](https://i.imgur.com/SjoLfuu.png)

描述器跟關鍵點的作法很像，把關鍵點周遭的一些區域，如左圖，有16個區域，對其方向作統計，但這邊只有8個方向（北、東北、東、東南、......），然後一樣要乘上高斯濾波的加權。
統計完成後如右圖，每一個小格有八個數字（分別代表八個方向的大小），又共有16個區域，所以描述器就會是$8\times 16 = 128$個維度的vector。

然而描述器的製作並不是直接把高斯圖片上關鍵點附近的區域直接拿來用，因為我們希望SIFT具有旋轉不變性(Rotational invariance)，所以必須要先將這些區域旋轉到關鍵點的主方向上，如圖：

![旋轉方向](https://i.imgur.com/8vFk5Yw.png)

有一個細節是，這個關鍵點的周遭區域要取多大？
可以看[影片](https://www.bilibili.com/video/BV1Qb411W7cK/?spm_id_from=333.788.videocard.0)

### Keypoint Matching（關鍵點匹配）
配對方式為利用KNN（k nearest neighbor）匹配距離最近的兩個關鍵點（一個從圖A一個從圖B），當然不一定要使用KNN，只是效率較高，也許可以採用Self-Organizing Map (SOM)之類的competitive learning？

在兩張影像中，如果要在第二張影像搜尋第一張影像的某個 keypoint，其搜尋方式就是透過該keypoint的descripto 與第二張影像的所有keypoints的descriptors來計算距離，通常距離最近的，
即為相同的 keypoint，但如果最近距離與第二近距離的比值大於0.8，則捨棄該keypoint，因為誤判的機率很大，該作法可以減少90%的誤判，然而代價是同時有5%的機會捨棄已經正確搜尋到的keypoints。

總結：
要匹配兩張圖的關鍵點，利用描述器。
而製作描述器，需要先利用關鍵點的主方向來旋轉圖片。

程式碼：
https://github.com/o0o0o0o0o0o0o/image-processing-from-scratch

參考資料：
1. https://blog.csdn.net/dcrmg/article/details/52561656
2. https://www.bilibili.com/video/BV1Qb411W7cK/?spm_id_from=333.788.videocard.0
3. https://slideplayer.com/slide/7868913/
4. https://www.programmersought.com/article/9600820411/